# src/clara_ssot/parsing/pdf_parser.py
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging
import os
import re
import uuid
import io
from PIL import Image
from collections import Counter

# PyMuPDF ì„í¬íŠ¸
import pymupdf

from .section_classifier import (
    SectionClassifier,
    SectionFeatures,
    extract_section_label,
    _normalize,
)

logger = logging.getLogger(__name__)


@dataclass
class BoundingBox:
    """PDF ì¢Œí‘œ ì •ë³´"""
    x0: float
    y0: float
    x1: float
    y1: float
    page: int

    def to_dict(self) -> Dict[str, float]:
        return {
            "x0": self.x0,
            "y0": self.y0,
            "x1": self.x1,
            "y1": self.y1,
            "page": self.page
        }


@dataclass
class ParsedBlock:
    page: int
    block_type: str
    text: Optional[str] = None
    bbox: Optional[BoundingBox] = None
    table_data: Optional[Dict] = None
    confidence: float = 1.0
    # ê³„ì¸µ êµ¬ì¡° í•„ë“œ
    level: int = 999          # 0: Title, 1: Section, 2+: Subsection, 999: Paragraph
    context_path: List[str] = field(default_factory=list)
    parent_id: Optional[str] = None
    block_id: Optional[str] = None
    # ì„¹ì…˜ ë©”íƒ€ë°ì´í„° (section_classifier ì—ì„œ ì¶”ì¶œ)
    section_label: Optional[str] = None   # ì˜ˆ: "1.2.3", "ì œ2ì¥"
    section_title: Optional[str] = None   # ë²ˆí˜¸ ì´í›„ ì œëª© í…ìŠ¤íŠ¸


@dataclass
class ParsedDocument:
    source_path: str
    blocks: List[ParsedBlock]
    metadata: Dict = None


class PyMuPDFParser:
    """
    í…ìŠ¤íŠ¸ ê¸°ë°˜ PDF íŒŒì„œ (PyMuPDF).

    íŒŒì´í”„ë¼ì¸:
      Phase 0 â€” ë¬¸ì„œ ë ˆë²¨ ì „ì²˜ë¦¬:
        - ë³¸ë¬¸ í°íŠ¸ í¬ê¸° ì¶”ì •
        - PDF ë¶ë§ˆí¬(Sê¸‰ íŒíŠ¸) ìˆ˜ì§‘
        - ToC í˜ì´ì§€ íŒŒì‹±(Sê¸‰ íŒíŠ¸) ì‹œë„
        - SectionClassifier ì´ˆê¸°í™”
      Phase 1 â€” ë¸”ë¡ ë£¨í”„:
        - ë¸”ë¡ íŠ¹ì§• ì¶”ì¶œ â†’ SectionClassifier.classify()
        - ìŠ¤íƒ ê¸°ë°˜ parent_id / context_path ì¶”ì 
    """

    def parse(self, pdf_path: Path) -> ParsedDocument:
        doc = pymupdf.open(pdf_path)
        blocks: List[ParsedBlock] = []

        # â”€â”€ Phase 0: ë¬¸ì„œ ë ˆë²¨ ì „ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        # ë³¸ë¬¸ í°íŠ¸ í¬ê¸° ì¶”ì • (ì „ì²´ span í°íŠ¸ í¬ê¸° ìµœë¹ˆê°’)
        font_sizes: List[float] = []
        for page in doc:
            for b in page.get_text("dict")["blocks"]:
                if b["type"] == 0:
                    for line in b["lines"]:
                        for span in line["spans"]:
                            if span["text"].strip():
                                font_sizes.append(round(span["size"], 1))

        body_font_size = Counter(font_sizes).most_common(1)[
            0][0] if font_sizes else 10.0
        logger.info(f"Detected body font size: {body_font_size}pt")

        # Sê¸‰ íŒíŠ¸ 1: PDF ë¶ë§ˆí¬
        pdf_bookmarks = doc.get_toc()   # [(level, title, page_no), ...]
        logger.info(f"PDF bookmarks found: {len(pdf_bookmarks)}")

        # Sê¸‰ íŒíŠ¸ 2: ToC í˜ì´ì§€ íŒŒì‹±
        toc_entries = self._extract_toc_entries(doc)
        logger.info(f"ToC entries parsed: {len(toc_entries)}")

        # ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        classifier = SectionClassifier(
            body_font_size, pdf_bookmarks, toc_entries)

        # â”€â”€ Phase 1: ë¸”ë¡ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        # ìŠ¤íƒ: [{"level": int, "id": str, "title": str}]
        context_stack: List[Dict] = []

        for page_index, page in enumerate(doc):
            page_dict = page.get_text("dict")
            page_width = page.rect.width

            for block in page_dict.get("blocks", []):
                if block["type"] != 0:   # 0: text, 1: image
                    continue

                # ë¸”ë¡ íŠ¹ì§• ì¶”ì¶œ
                text_parts: List[str] = []
                max_font_size = 0.0
                is_bold = False
                font_name_counter: Counter = Counter()

                for line in block["lines"]:
                    for span in line["spans"]:
                        text_parts.append(span["text"])
                        if span["size"] > max_font_size:
                            max_font_size = span["size"]
                        if span["flags"] & 16:   # bit 4 = bold
                            is_bold = True
                        if span["text"].strip():
                            font_name_counter[span["font"]] += 1

                clean_text = " ".join(text_parts).strip()
                if not clean_text:
                    continue

                dominant_font = (
                    font_name_counter.most_common(1)[0][0]
                    if font_name_counter else ""
                )
                bbox_x0, bbox_y0, bbox_x1, bbox_y1 = block["bbox"]

                # ë¶„ë¥˜ê¸° í˜¸ì¶œ
                features = SectionFeatures(
                    text=clean_text,
                    max_font_size=max_font_size,
                    is_bold=is_bold,
                    font_name=dominant_font,
                    page_width=page_width,
                    bbox_x0=bbox_x0,
                    bbox_x1=bbox_x1,
                )
                result = classifier.classify(features)

                # ìŠ¤íƒ ì¡°ì •: í˜„ì¬ ë ˆë²¨ë³´ë‹¤ ê¹Šê±°ë‚˜ ê°™ì€ ì´ì „ ì„¹ì…˜ ë‹«ê¸°
                level = result.level
                while context_stack and context_stack[-1]["level"] >= level:
                    context_stack.pop()

                # ë¶€ëª¨ ì—°ê²° ë° ì»¨í…ìŠ¤íŠ¸ ê²½ë¡œ ìˆ˜ì§‘
                parent_id = context_stack[-1]["id"] if context_stack else None
                current_context_path = [item["title"]
                                        for item in context_stack]
                block_id = str(uuid.uuid4())

                blocks.append(ParsedBlock(
                    page=page_index + 1,
                    block_type=result.block_type,
                    text=clean_text,
                    bbox=BoundingBox(
                        x0=bbox_x0, y0=bbox_y0,
                        x1=bbox_x1, y1=bbox_y1,
                        page=page_index + 1,
                    ),
                    confidence=result.confidence,
                    level=level,
                    context_path=current_context_path,
                    parent_id=parent_id,
                    block_id=block_id,
                    section_label=result.section_label,
                    section_title=result.section_title,
                ))

                # ì„¹ì…˜ë§Œ ìŠ¤íƒì— í‘¸ì‹œ (paragraphëŠ” ë¶€ëª¨ê°€ ë  ìˆ˜ ì—†ìŒ)
                if level < 999:
                    context_stack.append({
                        "level": level,
                        "id": block_id,
                        "title": clean_text,
                    })

        doc.close()

        return ParsedDocument(
            source_path=str(pdf_path),
            blocks=blocks,
            metadata={"parser": "pymupdf_section_classifier",
                      "version": "3.0.0"},
        )

    # â”€â”€ ë‚´ë¶€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _extract_toc_entries(self, doc) -> List[Dict]:
        """
        ToC í˜ì´ì§€ë¥¼ íƒì§€í•˜ê³  ì„¹ì…˜ ì—”íŠ¸ë¦¬ë¥¼ íŒŒì‹±í•œë‹¤.

        íƒì§€ ì „ëµ:
          - ì²« 15í˜ì´ì§€ì—ì„œ "contents" / "ëª©ì°¨" / "table of contents" í‚¤ì›Œë“œ ê²€ìƒ‰
          - ë°œê²¬ëœ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ë¼ì¸ì—ì„œ ì ì„ +í˜ì´ì§€ë²ˆí˜¸ ì œê±° í›„ ì„¹ì…˜ ë¼ë²¨ ì¶”ì¶œ

        ë°˜í™˜: [{"label": "1.2", "title": "Background"}, ...]
        """
        entries: List[Dict] = []

        for page_index, page in enumerate(doc):
            if page_index > 15:
                break

            page_text = page.get_text().strip()
            first_300 = page_text[:300].lower()

            toc_keywords = ("contents", "ëª©ì°¨", "table of contents")
            if not any(kw in first_300 for kw in toc_keywords):
                continue

            # ToC í˜ì´ì§€ ë°œê²¬ â†’ ë¼ì¸ë³„ íŒŒì‹±
            for line in page_text.split("\n"):
                line = line.strip()
                if len(line) < 3:
                    continue

                # ì ì„  ë° ë í˜ì´ì§€ ë²ˆí˜¸ ì œê±°
                # ì˜ˆ: "1.2 Background ............. 45" â†’ "1.2 Background"
                cleaned = re.sub(r"[.\s]{3,}\d+\s*$", "", line).strip()
                cleaned = re.sub(r"\.{3,}", "", cleaned).strip()

                if len(cleaned) < 3:
                    continue

                label, title = extract_section_label(cleaned)
                if label:
                    entries.append({"label": label, "title": title or cleaned})

            # ì²« ë²ˆì§¸ ToC í˜ì´ì§€ë§Œ ì²˜ë¦¬
            break

        return entries


class DoclingParser:
    """
    ë©”ì¸ íŒŒì„œ: Docling ê¸°ë°˜ (í‘œ + ë ˆì´ì•„ì›ƒ + ê³„ì¸µ êµ¬ì¡° ì „ë¬¸).

    Doclingì€ ìì²´ì ìœ¼ë¡œ ê³„ì¸µ êµ¬ì¡°ë¥¼ ì œê³µí•˜ë¯€ë¡œ SectionClassifierë¥¼ ìš°íšŒí•œë‹¤.
    section/title ë¸”ë¡ì— í•œí•´ extract_section_label()ë¡œ sectionLabel/sectionTitleì„ ì¶”ì¶œí•œë‹¤.
    """

    def __init__(self):
        try:
            from docling.document_converter import DocumentConverter, PdfFormatOption
            from docling.datamodel.base_models import InputFormat
            from docling.datamodel.pipeline_options import (
                PdfPipelineOptions,
                AcceleratorOptions,
                AcceleratorDevice,
            )
            import torch

            if torch.cuda.is_available():
                logger.info(
                    f"ğŸš€ GPU detected (CUDA: {torch.cuda.get_device_name(0)}). Using CUDA for Docling.")
                device = AcceleratorDevice.CUDA
            elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
                logger.info(
                    "ğŸš€ GPU detected (Apple MPS). Using MPS for Docling.")
                device = getattr(AcceleratorDevice, "MPS",
                                 AcceleratorDevice.CPU)
            else:
                logger.info(
                    "â„¹ï¸ GPU not detected (CUDA/MPS unavailable). Using CPU for Docling.")
                device = AcceleratorDevice.CPU

            pipeline_options = PdfPipelineOptions()
            pipeline_options.accelerator_options = AcceleratorOptions(
                num_threads=4, device=device
            )

            self.converter = DocumentConverter(
                format_options={InputFormat.PDF: PdfFormatOption(
                    pipeline_options=pipeline_options)}
            )

            try:
                import cv2  # noqa: F401
                self.converter.format_to_options[InputFormat.PDF].pipeline_options.do_table_structure = True
            except ImportError:
                logger.warning("OpenCV(cv2) ì—†ìŒ. í‘œ êµ¬ì¡° ì¶”ì¶œ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                self.converter.format_to_options[InputFormat.PDF].pipeline_options.do_table_structure = False

        except ImportError as e:
            raise ImportError(f"Docling ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")

    def parse(self, pdf_path: Path) -> ParsedDocument:
        result = self.converter.convert(pdf_path)
        doc = result.document
        blocks: List[ParsedBlock] = []

        context_stack: List[Dict] = []

        for item, level in doc.iterate_items():
            label = str(getattr(item, "label", "")).lower()
            text = getattr(item, "text", "").strip()

            if not text and "table" not in label:
                continue

            # íƒ€ì… ë§¤í•‘
            block_type = "paragraph"
            if "title" in label:
                block_type = "title"
            elif "header" in label:
                block_type = "section"
            elif "table" in label:
                block_type = "table"
            elif "list" in label:
                block_type = "list"

            # ìŠ¤íƒ ì¡°ì • (Docling levelì´ Noneì¸ ë³¸ë¬¸ì€ ìŠ¤íƒ ìœ ì§€)
            if block_type in ["title", "section"] and level is not None:
                while context_stack and context_stack[-1]["level"] >= level:
                    context_stack.pop()

            parent_id = context_stack[-1]["id"] if context_stack else None
            current_context_path = [item["title"] for item in context_stack]
            block_id = str(uuid.uuid4())

            # sectionLabel / sectionTitle ì¶”ì¶œ (Doclingì€ classifier ìš°íšŒ)
            sec_label, sec_title = None, None
            if block_type in ["title", "section"]:
                sec_label, sec_title = extract_section_label(text)
                if sec_title is None:
                    sec_title = text

            bbox = self._extract_bbox(item)

            parsed_block = ParsedBlock(
                page=item.prov[0].page_no if hasattr(
                    item, "prov") and item.prov else 1,
                block_type=block_type,
                text=text,
                bbox=bbox,
                confidence=1.0,
                level=level if level is not None else 999,
                context_path=current_context_path,
                parent_id=parent_id,
                block_id=block_id,
                section_label=sec_label,
                section_title=sec_title,
            )

            if block_type == "table" and hasattr(item, "export_to_dataframe"):
                try:
                    df = item.export_to_dataframe()
                    parsed_block.table_data = {
                        "headers": [str(h) for h in df.columns.tolist()],
                        "rows": [[str(c) for c in row] for row in df.values.tolist()]
                    }
                    parsed_block.text = df.to_markdown(index=False)
                except Exception:
                    pass

            blocks.append(parsed_block)

            if block_type in ["title", "section"] and level is not None:
                context_stack.append({
                    "level": level,
                    "id": block_id,
                    "title": text,
                })

        return ParsedDocument(
            source_path=str(pdf_path),
            blocks=blocks,
            metadata={"parser": "docling", "version": "2.0.0"},
        )

    def _extract_bbox(self, item) -> Optional[BoundingBox]:
        if hasattr(item, "prov") and item.prov:
            p = item.prov[0]
            b = p.bbox
            return BoundingBox(
                x0=getattr(b, "l", 0), y0=getattr(b, "b", 0),
                x1=getattr(b, "r", 0), y1=getattr(b, "t", 0),
                page=p.page_no,
            )
        return None


class GeminiVisionParser:
    """
    ë°±ì—… íŒŒì„œ: ìŠ¤ìº”ëœ ë¬¸ì„œë‚˜ ë³µì¡í•œ í‘œ ì²˜ë¦¬ë¥¼ ìœ„í•œ VLM (Vision-Language Model).
    gemini-3-flash-previewë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì¶”ì¶œ.
    """

    def __init__(self, api_key: str = None):
        from google import genai

        self.api_key = api_key or os.getenv(
            "GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if not self.api_key:
            raise ValueError("Gemini API Key is missing for Vision Parser.")

        self.client = genai.Client(api_key=self.api_key)
        self.model_name = "gemini-3-flash-preview"

    def parse(self, pdf_path: Path) -> ParsedDocument:
        """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ Geminiì—ê²Œ êµ¬ì¡°í™” ìš”ì²­."""
        doc = pymupdf.open(pdf_path)
        blocks: List[ParsedBlock] = []

        for page_index, page in enumerate(doc):
            if page_index >= 3:
                break

            pix = page.get_pixmap(dpi=150)
            img_data = pix.tobytes("png")
            image = Image.open(io.BytesIO(img_data))

            prompt = "Extract all text from this page. Return raw text."
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[prompt, image],
            )

            blocks.append(ParsedBlock(
                page=page_index + 1,
                block_type="paragraph",
                text=response.text,
                confidence=0.8,
            ))

        doc.close()

        return ParsedDocument(
            source_path=str(pdf_path),
            blocks=blocks,
            metadata={"parser": "gemini_vision", "version": "1.0.0"},
        )


def parse_pdf(path: Path) -> ParsedDocument:
    """
    í•˜ì´ë¸Œë¦¬ë“œ íŒŒì‹± ì „ëµ: Docling (ìµœìš°ì„ ) â†’ PyMuPDF â†’ Gemini Vision (ìŠ¤ìº”ë³¸)

    1. Docling: í‘œ, ë ˆì´ì•„ì›ƒ, ê³„ì¸µ êµ¬ì¡° ì™„ë²½ ì§€ì› (SectionClassifier ìš°íšŒ)
    2. PyMuPDF: ì•ˆì •ì  í…ìŠ¤íŠ¸ ì¶”ì¶œ + SectionClassifier ì ìš©
    3. Gemini Vision: ìŠ¤ìº” ë¬¸ì„œ ì „ìš© (ë¹„ìš© ë°œìƒ)
    """
    logger.info(f"Parsing PDF with Hybrid Strategy: {path}")

    try:
        doc = pymupdf.open(path)
        total_text_len = sum(len(page.get_text()) for page in doc)
        is_scanned = (len(doc) > 0) and (total_text_len / len(doc) < 50)
        doc.close()

        if not is_scanned:
            try:
                logger.info("ğŸš€ Docling íŒŒì„œ ì‹œë„ (í‘œ/êµ¬ì¡° ìµœì í™”)")
                return DoclingParser().parse(path)
            except Exception as e:
                logger.warning(
                    f"âš ï¸ Docling ì‹¤íŒ¨ ({e}). PyMuPDF + SectionClassifierë¡œ ì „í™˜.")
                return PyMuPDFParser().parse(path)
        else:
            logger.info("ğŸ–¼ï¸ Scanned PDF ê°ì§€: Gemini Vision(VLM) ì‚¬ìš©")
            if not (os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")):
                logger.warning("âš ï¸ Gemini API Key ì—†ìŒ. PyMuPDFë¡œ ê°•ì œ ì§„í–‰")
                return PyMuPDFParser().parse(path)
            return GeminiVisionParser().parse(path)

    except Exception as e:
        logger.warning(f"âš ï¸ íŒŒì‹± ì¤‘ ì—ëŸ¬ ({e}). PyMuPDF fallback ëª¨ë“œ.")
        return PyMuPDFParser().parse(path)
